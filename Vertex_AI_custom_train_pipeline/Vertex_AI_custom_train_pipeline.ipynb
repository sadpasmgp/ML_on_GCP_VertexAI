{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cf4d5-11d4-4564-a15b-ef850d5ae712",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794e045-621f-412c-bd87-e4747fb796f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install {USER_FLAG} google-cloud-aiplatform==1.7.0\n",
    "!pip3 install {USER_FLAG} kfp==1.8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fa698-0c84-4b26-a875-34865b8cb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b2244-e927-4c75-96a7-d19faf5660fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3bda9-92cc-4481-a645-cd5630faf491",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-pipeline\"\n",
    "BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf5bf3-a24b-483b-92d4-ee656db679ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# We'll use this namespace for metadata querying\n",
    "from google.cloud import aiplatform_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e8f21-df61-4ae4-a06b-c87806e4a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca4bd3-329f-4839-9aa4-79cca1ccee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Component in the pipeline to fetch data from big query.\n",
    "#Table1 data is fetched\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"dataset_creating_1.yaml\"\n",
    ")\n",
    "def get_data_1(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "\n",
    "    bqclient = bigquery.Client()\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b85c84-5a48-4463-9643-1653151ac366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Component in the pipeline to fetch data from big query.\n",
    "#Table2 data is fetched\n",
    "#First component and second component doesnt need inputs from any components\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"dataset_creating_2.yaml\"\n",
    ")\n",
    "def get_data_2(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "\n",
    "    bqclient = bigquery.Client()\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2a306-2d21-4736-9974-c3760da7ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third component in the pipeline to to combine data from 2 sources and for some data transformation\n",
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"model_training.yaml\",\n",
    ")\n",
    "def data_transformation(\n",
    "    dataset1: Input[Dataset],\n",
    "    dataset2: Input[Dataset],\n",
    "    output_data_path: OutputPath(\"Dataset\"),\n",
    "):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    \n",
    "    data1 = pd.read_csv(dataset1.path)\n",
    "    data2 = pd.read_csv(dataset2.path)\n",
    "    data=pd.merge(data1, data2, on='CLIENTNUM', how='outer')\n",
    "    data.drop([\"CLIENTNUM\"],axis=1,inplace=True)\n",
    "    cols_categorical = ['Gender','Dependent_count', 'Education_Level', 'Marital_Status','Income_Category','Card_Category']\n",
    "    data['Attrition_Flag'] = [1 if cust == \"Existing Customer\" else 0 for cust in data['Attrition_Flag']]\n",
    "    data_encoded = pd.get_dummies(data, columns = cols_categorical)\n",
    "    data_encoded.to_csv(output_data_path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5e90f-8371-4b8a-97b3-b704deb2a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth component in the pipeline to train the classification model using decision Trees or Randomforest\n",
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"model_training.yaml\",\n",
    ")\n",
    "def training_classmod(\n",
    "    data1: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    \n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import pandas as pd\n",
    "    \n",
    "    data_encoded=pd.read_csv(data1.path)\n",
    "    X = data_encoded.drop(columns=['Attrition_Flag'])\n",
    "    y = data_encoded['Attrition_Flag']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100,stratify=y)\n",
    "    model_classifier = DecisionTreeClassifier()\n",
    "    #model_classifier = RandomForestClassifier()\n",
    "    model_classifier.fit(X_train,y_train)\n",
    "    y_pred=model_classifier.predict(X_test)\n",
    "    score = model_classifier.score(X_test,y_test)\n",
    "    print('accuracy is:',score)\n",
    "    \n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"model\", \"Decision tree\")\n",
    "    #metrics.log_metric(\"model\", \"RandomForest\")\n",
    "    dump(model_classifier, model.path + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a30b32-4581-4d3b-9ec2-454e51cc23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"model_deployment.yaml\",\n",
    ")\n",
    "def model_deployment(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"custom-model-pipeline\",\n",
    "        artifact_uri = model.uri.replace(\"model\", \"\"), \n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3cab9-6136-42be-9ea2-31e3c63e306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"custom-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table_1: str = \"\",\n",
    "    bq_table_2: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    dataset_task_1 = get_data_1(bq_table_1)\n",
    "    dataset_task_2 = get_data_2(bq_table_2)\n",
    "    data_transform=data_transformation(dataset_task_1.output,dataset_task_2.output)\n",
    "\n",
    "    model_task = training_classmod(data_transform.output)\n",
    "\n",
    "    deploy_task = model_deployment(model=model_task.outputs[\"model\"],project=project,region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522d18d-f76b-4e79-aff1-2f57316ca094",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"custom-pipeline-classifier.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd7191-c784-4e70-a36b-6ea28a1e3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1 = aiplatform.PipelineJob(\n",
    "    display_name=\"custom-training-vertex-ai-pipeline\",\n",
    "    template_path=\"custom-pipeline-classifier.json\",\n",
    "    job_id=\"custom-pipeline-dt\",\n",
    "    #job_id=\"custom-pipeline-rf\",\n",
    "    parameter_values={\"bq_table_1\": \"vertex-ai-123.credit_card_churn.churner_p1\",\"bq_table_2\": \"vertex-ai-123.credit_card_churn.churner_p2\"},\n",
    "    enable_caching=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eec64c-8042-4e32-ace4-326473459b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3304e0-5283-4889-b0f2-3e83041e240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = aiplatform.get_pipeline_df(pipeline=\"vertex-ai-pipeline-custom-training\")\n",
    "#df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
